{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import sys\n",
    "from models import *\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Concatenate, Add, Conv2DTranspose, Input, Lambda, Reshape, LeakyReLU, Flatten, ReLU, Multiply, Subtract, Conv3D\n",
    "from tensorflow.keras.models import *\n",
    "import glob\n",
    "import random\n",
    "#import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.framework import ops\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train U-Net for each subsampled dataset\n",
    "for angle in [64, 128, 256, 512, 1024, 2048]:\n",
    "\n",
    "    save_path = os.path.abspath(\"./model_weights/U-Net/\") + f\"/{angle}/\"\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "        print(\"\\ncreated folder: \", save_path)\n",
    "\n",
    "    #Instantiate optimzers:\n",
    "    lr=1e-4\n",
    "    beta_1 = 0.9\n",
    "    beta_2 = 0.999\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr, beta_1=beta_1, beta_2=beta_2)\n",
    "\n",
    "    #load model\n",
    "    model = U_Net()\n",
    "    model.compile(optimizer=optimizer, loss=loss_UNet)\n",
    "    \n",
    "    #initiate data generator\n",
    "    filepath = os.path.abspath(f\"./Data/\")\n",
    "    train_list = pd.read_csv(os.path.abspath(\"./train_UNet.csv\"))['filename'].tolist()\n",
    "    val_list = pd.read_csv(os.path.abspath(\"./val_UNet.csv\"))['filename'].tolist()\n",
    "\n",
    "    batchsize = 32\n",
    "    \n",
    "    data_gen = load_batch(train_list, base_dir, batchsize=batchsize, angle=angle, shape=(256, 256))\n",
    "    data_gen_val = load_batch(val_list, base_dir, batchsize=batchsize, angle=angle, shape=(256, 256))\n",
    "    \n",
    "    #define callbacks\n",
    "    callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=save_path + '/model_{epoch:02d}.h5', verbose=1, period=5, save_weights_only=True), \n",
    "                tf.keras.callbacks.CSVLogger(save_path + '/log.csv', append=True, separator=','), \n",
    "                tf.keras.callbacks.LearningRateScheduler(step_decay, verbose=1)]\n",
    "    \n",
    "    #start training\n",
    "    model.fit(data_gen, epochs=75, steps_per_epoch=len(train_list)//batchsize, \n",
    "            validation_data = data_gen_val, validation_steps=len(val_list)//batchsize,\n",
    "            callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
